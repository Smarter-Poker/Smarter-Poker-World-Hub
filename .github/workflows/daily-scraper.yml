name: Venue Tournament Scraper (Daily)

on:
  schedule:
    # Run daily at 6am UTC (midnight CST)
    - cron: '0 6 * * *'
  workflow_dispatch:
    # Allow manual trigger with options
    inputs:
      mode:
        description: 'Scraping mode'
        required: true
        default: 'pokeratlas-daily'
        type: choice
        options:
          - pokeratlas-daily
          - full
          - test
          - setup-only
          - sync-urls-only
          - verify-venues
          - scrape-directory
      state:
        description: 'Filter by state (optional, e.g., TX, NV, FL)'
        required: false
        type: string

jobs:
  scrape-venue-tournaments:
    runs-on: ubuntu-latest
    timeout-minutes: 180  # 3 hour max for full scrape of 777 venues

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Sync Verified URLs to Database
        if: ${{ github.event_name == 'schedule' || github.event.inputs.mode != 'setup-only' }}
        env:
          NEXT_PUBLIC_SUPABASE_URL: ${{ secrets.NEXT_PUBLIC_SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        run: |
          echo "ğŸ”„ Syncing verified PokerAtlas URLs to database..."
          node scripts/sync-verified-urls.js

      - name: Skip Scraping (URL Sync Only)
        if: ${{ github.event.inputs.mode == 'sync-urls-only' }}
        run: echo "âœ… URL sync complete. Skipping scraping as requested."

      - name: Run PokerAtlas Daily Scraper (Scheduled)
        if: ${{ github.event_name == 'schedule' }}
        env:
          NEXT_PUBLIC_SUPABASE_URL: ${{ secrets.NEXT_PUBLIC_SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        run: |
          echo "=========================================="
          echo "POKERATLAS DAILY TOURNAMENT SCRAPER"
          echo "Source: data/tournament-venues.json (178 verified venues)"
          echo "Target: venue_daily_tournaments table"
          echo "=========================================="
          echo ""
          # Try HTTP scraper first (lighter, no Chrome needed)
          node scripts/pokeratlas-http-scraper.js || node scripts/pokeratlas-daily-scraper.js

      - name: Run PokerAtlas Daily Scraper (Manual)
        if: ${{ github.event_name == 'workflow_dispatch' && github.event.inputs.mode == 'pokeratlas-daily' }}
        env:
          NEXT_PUBLIC_SUPABASE_URL: ${{ secrets.NEXT_PUBLIC_SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        run: |
          echo "=========================================="
          echo "POKERATLAS DAILY TOURNAMENT SCRAPER"
          echo "=========================================="
          node scripts/pokeratlas-http-scraper.js ${{ github.event.inputs.state && format('--state {0}', github.event.inputs.state) || '' }}

      - name: Run Full Pipeline (Manual - Full)
        if: ${{ github.event_name == 'workflow_dispatch' && github.event.inputs.mode == 'full' }}
        env:
          NEXT_PUBLIC_SUPABASE_URL: ${{ secrets.NEXT_PUBLIC_SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        run: |
          echo "Running full venue tournament scraping pipeline..."
          echo "Triggered: $(date -u)"
          echo ""
          echo "Source 1: PokerAtlas"
          node scripts/run-full-pipeline.js --scrape-only
          echo ""
          echo "Source 2: Bravo Poker Live"
          node scripts/scrape-bravo-poker.js || echo "Bravo scraper had errors (non-fatal)"
          echo ""
          echo "Source 3: CardPlayer"
          node scripts/scrape-cardplayer.js || echo "CardPlayer scraper had errors (non-fatal)"

      - name: Run Pipeline (Manual - Test)
        if: ${{ github.event_name == 'workflow_dispatch' && github.event.inputs.mode == 'test' }}
        env:
          NEXT_PUBLIC_SUPABASE_URL: ${{ secrets.NEXT_PUBLIC_SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        run: |
          echo "ğŸ§ª Running test scrape (10 venues)..."
          node scripts/run-full-pipeline.js --test --scrape-only ${{ github.event.inputs.state && format('--state {0}', github.event.inputs.state) || '' }}

      - name: Run Pipeline (Manual - Setup Only)
        if: ${{ github.event_name == 'workflow_dispatch' && github.event.inputs.mode == 'setup-only' }}
        env:
          NEXT_PUBLIC_SUPABASE_URL: ${{ secrets.NEXT_PUBLIC_SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        run: |
          echo "ğŸ“¦ Running setup only..."
          node scripts/run-full-pipeline.js --setup-only

      - name: Verify Unverified Venues
        if: ${{ github.event_name == 'workflow_dispatch' && github.event.inputs.mode == 'verify-venues' }}
        env:
          NEXT_PUBLIC_SUPABASE_URL: ${{ secrets.NEXT_PUBLIC_SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        run: |
          echo "ğŸ” Running venue verification (checking multiple sources)..."
          node scripts/verify-all-venues.js 100

      - name: Scrape PokerAtlas Directory
        if: ${{ github.event_name == 'workflow_dispatch' && github.event.inputs.mode == 'scrape-directory' }}
        env:
          NEXT_PUBLIC_SUPABASE_URL: ${{ secrets.NEXT_PUBLIC_SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        run: |
          echo "ğŸ—ºï¸ Scraping PokerAtlas directory to get accurate venue URLs..."
          node scripts/scrape-pokeratlas-directory.js

      - name: Upload scraper logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: scraper-logs-${{ github.run_number }}
          path: |
            *.log
          retention-days: 7

      - name: Upload debug artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: debug-artifacts-${{ github.run_number }}
          path: |
            /tmp/venue-*.png
            /tmp/venue-*.html
          retention-days: 3
          if-no-files-found: ignore

      - name: Report Summary
        if: always()
        run: |
          echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
          echo "ğŸ“Š SCRAPER WORKFLOW COMPLETED"
          echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
          echo "Mode: ${{ github.event.inputs.mode || 'scheduled-full' }}"
          echo "State Filter: ${{ github.event.inputs.state || 'all' }}"
          echo "Completed at: $(date -u)"
          echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
